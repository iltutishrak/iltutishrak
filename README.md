## Hi, Im Ishrak Iltut  
**Product Builder at AWS Applied AI | Focused on Agentic and LLM Systems**

[![Python](https://img.shields.io/badge/Python-3776AB?style=flat-square&logo=python&logoColor=white)](https://www.python.org/)
[![AWS](https://img.shields.io/badge/AWS-232F3E?style=flat-square&logo=amazonaws&logoColor=white)](https://aws.amazon.com/)
![LLM](https://img.shields.io/badge/LLM-Agentic_AI-blue?style=flat-square)
![AI Product Management](https://img.shields.io/badge/AI_Product_Management-visionary-green?style=flat-square)
![Open Source](https://img.shields.io/badge/Open_Source-Building_Labs-black?style=flat-square)

---

I build reasoning-driven AI systems, focusing on orchestration, evaluation, governance, and explainability.  
I believe the best AI PMs do more than write PRDs. They prototype, test, and iterate.

---

###  What I Build
| Area | Focus |
|------|--------|
| З **Agentic Systems** | multi-agent orchestration, planning, simulation |
|  **Evaluation and Reliability** | LLM trust scoring, hallucination detection, reasoning metrics |
|  **Governance and Feedback** | bias audits, HITL loops, model transparency |
| О **PM Frameworks** | reusable templates and metrics guides for AI teams |

---

###  Featured Projects
| Repository | Description |
|-------------|-------------|
| [**agentic-reasoning-lab**](https://github.com/iltutishrak/agentic-reasoning-lab) | Multi-agent orchestration and RAG demo with reasoning loop. |
| [**llm-evaluation-playground**](https://github.com/iltutishrak/llm-evaluation-playground) | Mock scoring system for LLM accuracy, coherence, and hallucination. |
| [**feedback-loop-simulator**](https://github.com/iltutishrak/feedback-loop-simulator) | Simulated human-in-the-loop model feedback cycle. |
| [**data-lineage-demo**](https://github.com/iltutishrak/data-lineage-demo) | Tracks data flow and governance audit logs in AI systems. |
| [**model-governance-kit**](https://github.com/iltutishrak/model-governance-kit) | Simulates bias, fairness, and compliance checks for models. |
| [**agent-observability-demo**](https://github.com/iltutishrak/agent-observability-demo) | Logs and traces multi-agent interactions in text. |
| [**sandbox-orchestrator**](https://github.com/iltutishrak/sandbox-orchestrator) | Modular orchestration of multiple reasoning agents. |
| [**ai-simulation-framework**](https://github.com/iltutishrak/ai-simulation-framework) | Scenario simulation and decision evaluation sandbox. |
| [**ai-pm-templates**](https://github.com/iltutishrak/ai-pm-templates) | PRD, prompt, and evaluation templates for AI PMs. |
| [**ai-metrics-guide**](https://github.com/iltutishrak/-ai-metrics-guide) | Key reasoning and reliability metrics reference for PMs. |

---

### 锔 Tech and Tools
`Python` 路 `AWS` 路 `LangChain` 路 `Bedrock` 路 `Kendra` 路 `OpenAI` 路 `PyTorch` 路 `FAISS`  
`GitHub` 路 `Markdown` 路 `AI Evaluation` 路 `Agent Orchestration`

---

###  Connect
 **[linkedin.com/in/iltutishrak](https://linkedin.com/in/iltutishrak)**  
О **[github.com/iltutishrak](https://github.com/iltutishrak)**

---
